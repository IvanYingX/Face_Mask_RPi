{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\yingy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\nC:\\Users\\yingy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.4SP5SUA7CBGXUEOC35YP2ASOICYYEQZZ.gfortran-win_amd64.dll\nC:\\Users\\yingy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import cv2 \n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\yingy\\\\OneDrive\\\\Escritorio\\\\FaceMask_Model'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models/ckpt-16'\n",
    "LABEL_PATH = 'models/annotations/label_map.pbtxt'\n",
    "CONFIG_PATH = 'models/pipeline.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(MODEL_PATH).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(LABEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: {'id': 1, 'name': 'Mask'},\n",
       " 2: {'id': 2, 'name': 'NoMask'},\n",
       " 3: {'id': 3, 'name': 'NotProp'}}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "upperLeftCornerOfText = (10, 30)\n",
    "upperLeftCornerOfText2 = (10, 60)\n",
    "bottomLeftCornerOfText = (10, 450)\n",
    "fontScale = 1\n",
    "fontColor = (0,100,0)\n",
    "lineType = 2\n",
    "label_id_offset = 1\n",
    "try:\n",
    "    \n",
    "    j = 10\n",
    "    i = 0\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        message = f'Press \"s\" to start'\n",
    "        ret, frame = cap.read()\n",
    "        image_np = np.array(frame)\n",
    "\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "        detections = detect_fn(input_tensor)\n",
    "\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                      for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "\n",
    "        # detection_classes should be ints.\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "\n",
    "        image_np_with_detections = image_np.copy()\n",
    "\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                    image_np_with_detections,\n",
    "                    detections['detection_boxes'],\n",
    "                    detections['detection_classes']+label_id_offset,\n",
    "                    detections['detection_scores'],\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    max_boxes_to_draw=1,\n",
    "                    min_score_thresh=.5,\n",
    "                    agnostic_mode=False)\n",
    "        cv_toshow = cv2.resize(image_np_with_detections, (800, 600))\n",
    "        cv2.putText(cv_toshow, message, \n",
    "            upperLeftCornerOfText, \n",
    "            font,\n",
    "            fontScale,\n",
    "            fontColor,\n",
    "            lineType)\n",
    "        cv2.imshow('object detection',  cv_toshow)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        elif k == ord('s'):\n",
    "            time_start = time.time()\n",
    "            while True:\n",
    "                time_current = time.time() - time_start\n",
    "                countdown = round(3.4 - time_current)\n",
    "                message = f'Show your hand in {countdown}'\n",
    "                ret, frame = cap.read()\n",
    "                image_np = np.array(frame)\n",
    "\n",
    "                input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "                detections = detect_fn(input_tensor)\n",
    "\n",
    "                num_detections = int(detections.pop('num_detections'))\n",
    "                detections = {key: value[0, :num_detections].numpy()\n",
    "                              for key, value in detections.items()}\n",
    "                detections['num_detections'] = num_detections\n",
    "\n",
    "                # detection_classes should be ints.\n",
    "                detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "\n",
    "                image_np_with_detections = image_np.copy()\n",
    "\n",
    "                viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                            image_np_with_detections,\n",
    "                            detections['detection_boxes'],\n",
    "                            detections['detection_classes']+label_id_offset,\n",
    "                            detections['detection_scores'],\n",
    "                            category_index,\n",
    "                            use_normalized_coordinates=True,\n",
    "                            max_boxes_to_draw=1,\n",
    "                            min_score_thresh=.4,\n",
    "                            agnostic_mode=False)\n",
    "                cv_toshow = cv2.resize(image_np_with_detections, (800, 600))\n",
    "                cv2.putText(cv_toshow, message, \n",
    "                    upperLeftCornerOfText, \n",
    "                    font,\n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "                cv2.imshow('object detection',  cv_toshow)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break\n",
    "                if countdown <= 0:\n",
    "                    time_1 = time.time()\n",
    "                    decision = category_index[random.choice(list(category_index.keys()))]['name']\n",
    "                    while True:\n",
    "                        time_within = time.time() - time_1\n",
    "                        ret, frame = cap.read()\n",
    "                        image_np = np.array(frame)\n",
    "                        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "                        detections = detect_fn(input_tensor)\n",
    "                        num_detections = int(detections.pop('num_detections'))\n",
    "                        detections = {key: value[0, :num_detections].numpy()\n",
    "                              for key, value in detections.items()}\n",
    "                        detections['num_detections'] = num_detections\n",
    "                        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "                        image_np_with_detections = image_np.copy()\n",
    "                        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                            image_np_with_detections,\n",
    "                            detections['detection_boxes'],\n",
    "                            detections['detection_classes']+label_id_offset,\n",
    "                            detections['detection_scores'],\n",
    "                            category_index,\n",
    "                            use_normalized_coordinates=True,\n",
    "                            max_boxes_to_draw=1,\n",
    "                            min_score_thresh=.4,\n",
    "                            agnostic_mode=False)\n",
    "                        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                            cap.release()\n",
    "                            cv2.destroyAllWindows()\n",
    "                            break\n",
    "                        cv_toshow = cv2.resize(image_np_with_detections, (800, 600))\n",
    "                        cv2.putText(cv_toshow, f'I am choosing: {decision}.', \n",
    "                            upperLeftCornerOfText, \n",
    "                            font,\n",
    "                            fontScale,\n",
    "                            fontColor,\n",
    "                            lineType)\n",
    "                        cv2.imshow('object detection',  cv_toshow)\n",
    "                        if time_within > 0.5:\n",
    "                            time_2 = time.time()\n",
    "                            user_decision = category_index[(detections['detection_classes']+label_id_offset)[0]]['name']\n",
    "                            while True:\n",
    "                                time_within = time.time() - time_2\n",
    "                                ret, frame = cap.read()\n",
    "                                image_np = np.array(frame)\n",
    "                                image_toshow = cv2.resize(image_np, (800, 600))\n",
    "                                cv2.putText(image_toshow, f'I am choosing: {decision}.', \n",
    "                                    upperLeftCornerOfText, \n",
    "                                    font,\n",
    "                                    fontScale,\n",
    "                                    fontColor,\n",
    "                                    lineType)\n",
    "                                cv2.putText(image_toshow, f'You chose {user_decision}.', \n",
    "                                    upperLeftCornerOfText2, \n",
    "                                    font,\n",
    "                                    fontScale,\n",
    "                                    fontColor,\n",
    "                                    lineType)\n",
    "                                cv2.imshow('object detection', image_toshow)\n",
    "                                if time_within > 3:\n",
    "                                    break\n",
    "                                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                                    cap.release()\n",
    "                                    cv2.destroyAllWindows()\n",
    "                                    break\n",
    "                            break\n",
    "\n",
    "                    time_start = time.time()\n",
    "        \n",
    "        \n",
    "except:\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['detection_boxes', 'detection_scores', 'detection_classes', 'raw_detection_boxes', 'raw_detection_scores', 'detection_multiclass_scores', 'detection_anchor_indices', 'num_detections'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7493779 , 0.0757446 , 0.07273477, 0.06574634, 0.05184636,\n",
       "       0.05139107, 0.05022532, 0.04096368, 0.038109  , 0.03804481,\n",
       "       0.03705531, 0.03486669, 0.03170073, 0.02871361, 0.02862534,\n",
       "       0.02852809, 0.02644783, 0.0263795 , 0.02613997, 0.02584374,\n",
       "       0.02524531, 0.0249882 , 0.02454662, 0.02410406, 0.02387947,\n",
       "       0.02359322, 0.02334237, 0.02327237, 0.02271512, 0.02172542,\n",
       "       0.02162555, 0.02129379, 0.0212481 , 0.02103397, 0.02063909,\n",
       "       0.0206289 , 0.02044153, 0.01955476, 0.01935366, 0.01926675,\n",
       "       0.01924458, 0.01847324, 0.01831242, 0.01763806, 0.01749778,\n",
       "       0.01746088, 0.01738372, 0.01704475, 0.01686808, 0.0167166 ,\n",
       "       0.01634231, 0.01608232, 0.01605856, 0.01592144, 0.01579261,\n",
       "       0.0157325 , 0.01562235, 0.0155465 , 0.01553187, 0.0154134 ,\n",
       "       0.01524556, 0.01522401, 0.01520467, 0.01519942, 0.01511937,\n",
       "       0.01498556, 0.01495937, 0.0149084 , 0.01485813, 0.01473564,\n",
       "       0.01464534, 0.0146409 , 0.01440626, 0.01433784, 0.01426089,\n",
       "       0.01411864, 0.01402462, 0.01367763, 0.01362571, 0.01352337,\n",
       "       0.01344019, 0.01342049, 0.01322407, 0.01310369, 0.0129379 ,\n",
       "       0.01288849, 0.01278883, 0.01274508, 0.01263943, 0.01249927,\n",
       "       0.01245865, 0.01237866, 0.01237184, 0.01234332, 0.01233032,\n",
       "       0.0122267 , 0.01214302, 0.01211339, 0.01197177, 0.01195818],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections['detection_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2,\n",
       "       0, 2, 2, 1, 1, 2, 0, 2, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2,\n",
       "       1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2,\n",
       "       2, 0, 2, 1, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0,\n",
       "       0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections['detection_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfodj",
   "language": "python",
   "name": "tfodj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}