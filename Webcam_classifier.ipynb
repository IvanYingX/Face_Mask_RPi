{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd04c16d4709914fb96df173483f15d375ad59ae5b8d3e471a3f8edc161b856b714",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e6aa97b189a35e29c1529870d6fcb1f70dba8daac1478ee0bd56bd55187cdcb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tensorflow.keras.models.load_model('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# # Replace this with the path to your image\n",
    "# image = Image.open('test_nomask.jpg')\n",
    "\n",
    "# #resize the image to a 224x224 with the same strategy as in TM2:\n",
    "# #resizing the image to be at least 224x224 and then cropping from the center\n",
    "# size = (224, 224)\n",
    "# image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "# #turn the image into a numpy array\n",
    "# image_array = np.asarray(image)\n",
    "\n",
    "# data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# # Replace this with the path to your image\n",
    "# image = Image.open('test_nomask.jpg')\n",
    "\n",
    "# #resize the image to a 224x224 with the same strategy as in TM2:\n",
    "# #resizing the image to be at least 224x224 and then cropping from the center\n",
    "# size = (224, 224)\n",
    "# image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "# #turn the image into a numpy array\n",
    "# image_array = np.asarray(image)\n",
    "\n",
    "# # display the resized image\n",
    "# image.show()\n",
    "\n",
    "# # Normalize the image\n",
    "# normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "# # Load the image into the array\n",
    "# data[0] = normalized_image_array\n",
    "\n",
    "# # run the inference\n",
    "# prediction = model.predict(data)\n",
    "# print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "size = (224, 224)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,500)\n",
    "fontScale = 1\n",
    "fontColor = (255,255,255)\n",
    "lineType = 2\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Format the image into a PIL Image so its compatable with Edge TPU\n",
    "        cv2_im = frame\n",
    "        pil_im = Image.fromarray(cv2_im)\n",
    "\n",
    "        # Resize and flip image so its a square and matches training\n",
    "        image = ImageOps.fit(pil_im, size, Image.ANTIALIAS)\n",
    "        image_array = np.asarray(image)\n",
    "        normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "        data[0] = normalized_image_array\n",
    "        # Classify and display image\n",
    "        prediction = model.predict(data)\n",
    "        cv2.putText(img,prediction, \n",
    "            bottomLeftCornerOfText, \n",
    "            font, \n",
    "            fontScale,\n",
    "            fontColor,\n",
    "            lineType)\n",
    "        cv2.imshow('frame', cv2_im)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.2300567  0.76994336]]\n",
      "[[0.61330646 0.38669357]]\n",
      "[[0.6119297  0.38807032]]\n",
      "[[0.12046926 0.8795307 ]]\n",
      "[[0.5443058  0.45569417]]\n",
      "[[0.38469505 0.6153049 ]]\n",
      "[[0.37220523 0.6277947 ]]\n",
      "[[0.46681848 0.53318155]]\n",
      "[[0.3983925 0.6016075]]\n",
      "[[0.36427513 0.6357249 ]]\n",
      "[[0.46075806 0.53924197]]\n",
      "[[0.42233643 0.57766354]]\n",
      "[[0.01039701 0.989603  ]]\n",
      "[[0.00501495 0.9949851 ]]\n",
      "[[0.00883977 0.9911602 ]]\n",
      "[[0.02304903 0.97695094]]\n",
      "[[0.03661093 0.96338904]]\n",
      "[[0.19858027 0.80141973]]\n",
      "[[0.03258249 0.96741754]]\n",
      "[[0.00259038 0.99740964]]\n",
      "[[0.0629347  0.93706536]]\n",
      "[[0.02752547 0.9724745 ]]\n",
      "[[0.01494226 0.9850578 ]]\n",
      "[[0.00446441 0.9955356 ]]\n",
      "[[0.00181125 0.9981888 ]]\n",
      "[[0.00509496 0.994905  ]]\n",
      "[[0.01240516 0.98759484]]\n",
      "[[0.00806021 0.99193984]]\n",
      "[[0.01810925 0.98189074]]\n",
      "[[0.06299918 0.93700075]]\n",
      "[[0.01038998 0.98960996]]\n",
      "[[0.00818448 0.9918155 ]]\n",
      "[[0.21701218 0.78298783]]\n",
      "[[0.9325966  0.06740333]]\n",
      "[[0.99910825 0.00089174]]\n",
      "[[0.99964786 0.00035216]]\n",
      "[[0.99983025 0.00016975]]\n",
      "[[0.99999666 0.00000336]]\n",
      "[[0.9999795  0.00002054]]\n",
      "[[0.9999809  0.00001903]]\n",
      "[[0.9998342  0.00016583]]\n",
      "[[0.99997497 0.00002505]]\n",
      "[[0.9998412 0.0001588]]\n",
      "[[0.999941   0.00005902]]\n",
      "[[0.9999944  0.00000565]]\n",
      "[[0.99998665 0.00001336]]\n",
      "[[0.9999949  0.00000507]]\n",
      "[[0.99999475 0.00000519]]\n",
      "[[0.9999932  0.00000677]]\n",
      "[[0.9999918  0.00000818]]\n",
      "[[0.99999154 0.00000849]]\n",
      "[[0.99999666 0.00000333]]\n",
      "[[0.99999654 0.00000347]]\n",
      "[[0.999997   0.00000296]]\n",
      "[[0.99999666 0.0000033 ]]\n",
      "[[0.9999654  0.00003459]]\n",
      "[[0.9990357  0.00096435]]\n",
      "[[0.03734012 0.96265996]]\n",
      "[[0.06245606 0.9375439 ]]\n",
      "[[0.04704716 0.9529528 ]]\n",
      "[[0.03124202 0.968758  ]]\n",
      "[[0.02205015 0.9779498 ]]\n",
      "[[0.00841243 0.9915876 ]]\n",
      "[[0.00551724 0.99448276]]\n",
      "[[0.00578784 0.9942121 ]]\n",
      "[[0.01161766 0.9883823 ]]\n",
      "[[0.01061105 0.9893889 ]]\n",
      "[[0.00774544 0.9922545 ]]\n",
      "[[0.00755324 0.9924468 ]]\n",
      "[[0.00951538 0.9904846 ]]\n",
      "[[0.00844987 0.9915501 ]]\n",
      "[[0.01123711 0.9887629 ]]\n",
      "[[0.01028771 0.98971224]]\n",
      "[[0.00952511 0.9904749 ]]\n",
      "[[0.01361738 0.9863826 ]]\n",
      "[[0.01200388 0.98799616]]\n",
      "[[0.0130291 0.9869709]]\n",
      "[[0.01356519 0.9864348 ]]\n",
      "[[0.00980561 0.9901944 ]]\n",
      "[[0.01213747 0.9878626 ]]\n",
      "[[0.00393302 0.996067  ]]\n",
      "[[0.00432179 0.99567825]]\n",
      "[[0.00342123 0.99657875]]\n",
      "[[0.00095759 0.99904233]]\n",
      "[[0.00282988 0.99717015]]\n",
      "[[0.00754633 0.99245363]]\n",
      "[[0.0054529 0.9945471]]\n",
      "[[0.00075281 0.9992472 ]]\n",
      "[[0.00788897 0.99211097]]\n",
      "[[0.00680433 0.99319565]]\n",
      "[[0.0063035 0.9936965]]\n",
      "[[0.00196069 0.9980393 ]]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}